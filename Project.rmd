---
title: "2501 Project"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Name and UID

Name: Ng Kin Hei

UID: 3036067418

------------------------------------------------------------------------

```{r}
install.packages("reshape2")
library(reshape2)


```

```{r}
install.packages("tidyr")
install.packages("syuzhet")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("textcat")
install.packages("wordcloud")
install.packages("tm")
install.packages("RColorBrewer")
install.packages("wordcloud2")
install.packages("tidytext")
```

### Environmental setup

```{r}
# Load the package.
library(tidyr)
library(dplyr)
library(ggplot2)
library(textcat)
library(wordcloud)
library(tm)
library(RColorBrewer)
library(wordcloud2)
library(syuzhet)
library(stringr)
library(tidytext)
```

### Read the dataset

```{r}
project_data <- read.csv("/Users/gordon/Downloads/Project/Fake_News_Patterns_Analysation/WELFake_Dataset.csv")
#fake_news_testing <- read.csv("/Users/gordon/Downloads/fake_news_testing.csv")
#real_news_testing <- read.csv("/Users/gordon/Downloads/real_news_testing.csv")
```

### Detect language

```{r}
#language detection for text and title

my.profiles <- TC_byte_profiles[names(TC_byte_profiles)]

project_data$title_language <- textcat(project_data$title, p = my.profiles)
project_data$text_language <- textcat(project_data$text, p = my.profiles)

#filter out all news that the text is in english
filter_data <- filter(project_data, text_language == "english")


```

### Clean the data first

```{r}
#structure
#str(project_data)

# Check for blank spaces in each column
#blank_spaces <- apply(project_data, 2, function(x) any(grepl("^\\s*$", x)))

# Count blank spaces in the "title" column
blank_spaces_title <- sum(grepl("^\\s*$", filter_data$title))
blank_spaces_title

# Count blank spaces in the "text" column
blank_spaces_text <- sum(grepl("^\\s*$", filter_data$text))
blank_spaces_text

# Subset the data frame to exclude rows with blank spaces in the "title" column
filter_data <- filter_data[!grepl("^\\s*$", filter_data$title), ]

# Subset the data frame to exclude rows with blank spaces in the "text" column
filter_data <- filter_data[!grepl("^\\s*$", filter_data$text), ]

#Rename the filter_data label to "fake" and "real"
filter_data <- filter_data %>%
  mutate(label = ifelse(label == 0, "real", "fake"))

#count number of fake news and true news
filter_data %>% group_by(label) %>% summarise(count = n())

```

### Data Visualization

```{r}
#Show the amount of fake and real news
## balance data amount
ggplot(filter_data, aes(x = label, fill = factor(label))) +
  geom_bar() +
  theme_minimal()
```

```{r}
#Scatterplot for text length
ggplot(filter_data, aes(x=label, y=nchar(text), color=label)) + 
    geom_jitter() +
    theme_minimal() +
    labs(y="Text length")

#Scatterplot for title length
ggplot(filter_data, aes(x=label, y=nchar(title), color=label)) + 
    geom_jitter() +
    theme_minimal() +
    labs(y="Title length")
```

### We need to build a corpus, which is a collection of documents, from the texts.

```{r}
#dataset of real and fake news
real_news <- filter(filter_data, label == "real")
fake_news <- filter(filter_data, label == "fake")

real_news_testing <- real_news %>% sample_n(30000, replace = FALSE)
fake_news_testing <- fake_news %>% sample_n(30000, replace = FALSE)


#Remove stop words
remove_stopwords <- function(text) {
  corpus <- Corpus(VectorSource(text))
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "", "'s"))
  
  # Get the cleaned text from the corpus
  cleaned_text <- sapply(corpus, function(x) gsub("[|\\-\\–—\\“\\”]|’S|’s", "", x))
  
  return(cleaned_text)
}

# Apply the remove_stopwords function to the text column and create a new column
real_news_testing$cleaned_text <- remove_stopwords(real_news_testing$text)
fake_news_testing$cleaned_text <- remove_stopwords(fake_news_testing$text)



#Wordcloud of real news
wordcloud(real_news_testing$cleaned_text, min.freq = 1,
          max.words=150, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


#Wordcloud of fake news
wordcloud(fake_news_testing$cleaned_text, min.freq = 1,
          max.words=150, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

### amount of Question marks and exclamation mark

```{r}
# Count exclamation marks in text and title for real_news_testing
real_news_testing$exclamation_count_text <- sapply(real_news_testing$text, function(x) length(unlist(strsplit(as.character(x), "\\!+"))))
real_news_testing$exclamation_count_title <- sapply(real_news_testing$title, function(x) length(unlist(strsplit(as.character(x), "\\!+"))))

# Count exclamation marks in text and title for fake_news_testing
fake_news_testing$exclamation_count_text <- sapply(fake_news_testing$text, function(x) length(unlist(strsplit(as.character(x), "\\!+"))))
fake_news_testing$exclamation_count_title <- sapply(fake_news_testing$title, function(x) length(unlist(strsplit(as.character(x), "\\!+"))))

# Count question marks in text and title for real_news_testing
real_news_testing$question_mark_count_text <- sapply(real_news_testing$text, function(x) length(unlist(strsplit(as.character(x), "\\?+"))))
real_news_testing$question_mark_count_title <- sapply(real_news_testing$title, function(x) length(unlist(strsplit(as.character(x), "\\?+"))))

# Count question marks in text and title for fake_news_testing
fake_news_testing$question_mark_count_text <- sapply(fake_news_testing$text, function(x) length(unlist(strsplit(as.character(x), "\\?+"))))
fake_news_testing$question_mark_count_title <- sapply(fake_news_testing$title, function(x) length(unlist(strsplit(as.character(x), "\\?+"))))

# Summarize counts by label for real_news_testing
exclamations_summary_real <- real_news_testing %>% 
  group_by(label) %>% 
  summarise(exclamations_in_text = sum(exclamation_count_text),
            exclamations_in_title = sum(exclamation_count_title))

question_marks_summary_real <- real_news_testing %>% 
  group_by(label) %>% 
  summarise(question_marks_in_text = sum(question_mark_count_text),
            question_marks_in_title = sum(question_mark_count_title))

# Summarize counts by label for fake_news_testing
exclamations_summary_fake <- fake_news_testing %>% 
  group_by(label) %>% 
  summarise(exclamations_in_text = sum(exclamation_count_text),
            exclamations_in_title = sum(exclamation_count_title))

question_marks_summary_fake <- fake_news_testing %>% 
  group_by(label) %>% 
  summarise(question_marks_in_text = sum(question_mark_count_text),
            question_marks_in_title = sum(question_mark_count_title))

# Combine the summaries for real and fake news testing datasets
exclamations_summary_combined <- bind_rows(
  mutate(exclamations_summary_real),
  mutate(exclamations_summary_fake)
)
exclamations_summary_combined

questions_summary_combined <- bind_rows(
  mutate(question_marks_summary_real),
  mutate(question_marks_summary_fake)
)
questions_summary_combined

```

```{r}
# Plot for question marks in text
ggplot(data = questions_summary_combined, aes(x = label, y = question_marks_in_text, fill = label)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Question Marks in Text", x = "Label", y = "Count") +
  theme_minimal()

# Plot for question marks in title
ggplot(data = questions_summary_combined, aes(x = label, y = question_marks_in_title, fill = label)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Question Marks in Title", x = "Label", y = "Count") +
  theme_minimal()

# Plot for ! marks in text
ggplot(data = exclamations_summary_combined, aes(x = label, y = exclamations_in_text, fill = label)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Exclamation Marks in Text", x = "Label", y = "Count") +
  theme_minimal()

# Plot for ! marks in title
ggplot(data = exclamations_summary_combined, aes(x = label, y = exclamations_in_title, fill = label)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Exclamation Marks in Title", x = "Label", y = "Count") +
  theme_minimal()




```

```{r}
#mean and standard deviation for real news dataset

# Calculate mean of exclamation marks for real and fake news datasets
mean_exclamation_real <- mean(real_news_testing$exclamation_count_text + real_news_testing$exclamation_count_title)
mean_exclamation_fake <- mean(fake_news_testing$exclamation_count_text + fake_news_testing$exclamation_count_title)

# Calculate mean of question marks for real and fake news datasets
mean_question_real <- mean(real_news_testing$question_mark_count_text + real_news_testing$question_mark_count_title)
mean_question_fake <- mean(fake_news_testing$question_mark_count_text + fake_news_testing$question_mark_count_title)

# Calculate standard deviation of exclamation marks for real and fake news datasets
sd_exclamation_real <- sd(real_news_testing$exclamation_count_text + real_news_testing$exclamation_count_title)
sd_exclamation_fake <- sd(fake_news_testing$exclamation_count_text + fake_news_testing$exclamation_count_title)

# Calculate standard deviation of question marks for real and fake news datasets
sd_question_real <- sd(real_news_testing$question_mark_count_text + real_news_testing$question_mark_count_title)
sd_question_fake <- sd(fake_news_testing$question_mark_count_text + fake_news_testing$question_mark_count_title)

# Create a summary table with means and standard deviations
summary_table <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Mean_Exclamation = c(mean_exclamation_real, mean_exclamation_fake),
  SD_Exclamation = c(sd_exclamation_real, sd_exclamation_fake),
  Mean_Question = c(mean_question_real, mean_question_fake),
  SD_Question = c(sd_question_real, sd_question_fake)
)
summary_table



# Create a dataframe for plotting
plot_data <- data.frame(
  Dataset = c("Real News", "Fake News", "Real News", "Fake News"),
  Measure = rep(c("Exclamation Marks", "Question Marks"), each = 2),
  Mean = c(mean_exclamation_real, mean_exclamation_fake, mean_question_real, mean_question_fake),
  SD = c(sd_exclamation_real, sd_exclamation_fake, sd_question_real, sd_question_fake)
)

# Create the bar plot
ggplot(plot_data, aes(x = Dataset, y = Mean, fill = Measure)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.5) +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Mean Counts of Exclamation Marks and Question Marks",
       y = "Mean Count",
       fill = "Measure") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

###Sentiment Analysis

```{r}
#create sentiment table for text column
real_news_sentiment<-get_nrc_sentiment(real_news_testing$cleaned_text)
real_news_sentiment
fake_news_sentiment<-get_nrc_sentiment(fake_news_testing$cleaned_text)
fake_news_sentiment
```

```{r}
real_news_testing <- cbind(real_news_testing, real_news_sentiment)
fake_news_testing <- cbind(fake_news_testing, fake_news_sentiment)

```

```{r}
# For real news dataset
real_total_positive <- sum(real_news_testing$positive)
real_total_negative <- sum(real_news_testing$negative)
real_total_anger <- sum(real_news_testing$anger)
real_total_disgust <- sum(real_news_testing$disgust)
real_total_sadness <- sum(real_news_testing$sadness)
real_total_fear <- sum(real_news_testing$fear)

real_mean_positive <- mean(real_news_testing$positive)
real_mean_negative <- mean(real_news_testing$negative)
real_mean_anger <- mean(real_news_testing$anger)
real_mean_disgust <- mean(real_news_testing$disgust)
real_mean_sadness <- mean(real_news_testing$sadness)
real_mean_fear <- mean(real_news_testing$fear)

real_sd_positive <- sd(real_news_testing$positive)
real_sd_negative <- sd(real_news_testing$negative)
real_sd_anger <- sd(real_news_testing$anger)
real_sd_disgust <- sd(real_news_testing$disgust)
real_sd_sadness <- sd(real_news_testing$sadness)
real_sd_fear <- sd(real_news_testing$fear)

# For fake news dataset
fake_total_positive <- sum(fake_news_testing$positive)
fake_total_negative <- sum(fake_news_testing$negative)
fake_total_anger <- sum(fake_news_testing$anger)
fake_total_disgust <- sum(fake_news_testing$disgust)
fake_total_sadness <- sum(fake_news_testing$sadness)
fake_total_fear <- sum(fake_news_testing$fear)

fake_mean_positive <- mean(fake_news_testing$positive)
fake_mean_negative <- mean(fake_news_testing$negative)
fake_mean_anger <- mean(fake_news_testing$anger)
fake_mean_disgust <- mean(fake_news_testing$disgust)
fake_mean_sadness <- mean(fake_news_testing$sadness)
fake_mean_fear <- mean(fake_news_testing$fear)

fake_sd_positive <- sd(fake_news_testing$positive)
fake_sd_negative <- sd(fake_news_testing$negative)
fake_sd_anger <- sd(fake_news_testing$anger)
fake_sd_disgust <- sd(fake_news_testing$disgust)
fake_sd_sadness <- sd(fake_news_testing$sadness)
fake_sd_fear <- sd(fake_news_testing$fear)




# Summarize total scores of positive and negative for real and fake datasets
total_scores <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Total_Positive = c(real_total_positive, fake_total_positive),
  Total_Negative = c(real_total_negative, fake_total_negative),
  Total_Anger = c(real_total_anger, fake_total_anger),
  Total_Disgust = c(real_total_disgust, fake_total_disgust),
  Total_Sadness = c(real_total_sadness, fake_total_sadness),
  Total_Fear = c(real_total_fear, fake_total_fear)
)

# Summarize mean and standard deviation of positive, negative, anger, disgust, sadness, and fear for real and fake datasets
mean_sd <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Mean_Positive = c(real_mean_positive, fake_mean_positive),
  SD_Positive = c(real_sd_positive, fake_sd_positive),
  Mean_Negative = c(real_mean_negative, fake_mean_negative),
  SD_Negative = c(real_sd_negative, fake_sd_negative),
  Mean_Anger = c(real_mean_anger, fake_mean_anger),
  SD_Anger = c(real_sd_anger, fake_sd_anger),
  Mean_Disgust = c(real_mean_disgust, fake_mean_disgust),
  SD_Disgust = c(real_sd_disgust, fake_sd_disgust),
  Mean_Sadness = c(real_mean_sadness, fake_mean_sadness),
  SD_Sadness = c(real_sd_sadness, fake_sd_sadness),
  Mean_Fear = c(real_mean_fear, fake_mean_fear),
  SD_Fear = c(real_sd_fear, fake_sd_fear)
)




# Display the summaries
cat("Summary of Total Scores:\n")
print(total_scores)

cat("\nSummary of Mean and SD:\n")
print(mean_sd)
```

```{r}
# Reshape data for plotting
# Filter the data frame to include only the rows corresponding to SD
sd_data <- mean_sd_long[grep("SD_", mean_sd_long$variable), ]



# Plot
ggplot(data = sd_data, aes(x = variable, y = value, group = Dataset, color = Dataset)) +
  geom_line() +
  geom_point() +
  labs(title = "Standard Deviation of Different Sentiments",
       x = "Sentiment",
       y = "Standard Deviation") +
  scale_color_manual(values = c("Real News" = "blue", "Fake News" = "red")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

###Find Sentiment (Positive - negative)

```{r}
# Define the function to perform sentiment analysis
GetSentiment <- function(cleaned_text){
    # Tokenize the text column
    tokens <- data_frame(text = cleaned_text) %>% unnest_tokens(word, text)
    # Get the sentiment from the text
    sentiment_table <- tokens %>%
      inner_join(get_sentiments("bing")) %>%
      count(sentiment) %>%
      spread(sentiment, n, fill = 0)
    
    if (sum(sentiment_table$negative) == 0) {
      return(0)}

    if (!"negative" %in% colnames(sentiment_table)) {
      # If it doesn't exist, add it and assign 0 to all its values
      sentiment_table <- sentiment_table %>%
      mutate(negative = 0)
    }
    if (!"positive" %in% colnames(sentiment_table)) {
      # If it doesn't exist, add it and assign 0 to all its values
      sentiment_table <- sentiment_table %>%
      mutate(positive = 0)}
    sentiment_table <- sentiment_table %>%  mutate(sentiment = positive - negative) 
    rm(tokens)
    # Return the modified data fram
    return(sentiment_table$sentiment)
}
fake_news_testing$sentiment <- sapply(fake_news_testing$cleaned_text, GetSentiment)
real_news_testing$sentiment <- sapply(real_news_testing$cleaned_text, GetSentiment)


```

```{r pressure, echo=FALSE}
neg_sentiment_real <- sum(real_news_testing$sentiment < 0)
neg_sentiment_fake <- sum(fake_news_testing$sentiment < 0)
paste("Number of Neg>Pos (real): ",neg_sentiment_real)
paste("Number of Neg>Pos (fake): ",neg_sentiment_fake)

# Summary for real news sentiment
summary_real <- summary(real_news_testing$sentiment)
cat("Summary for Real News Sentiment:\n")
print(summary_real)

# Summary for fake news sentiment
summary_fake <- summary(fake_news_testing$sentiment)
cat("\nSummary for Fake News Sentiment:\n")
print(summary_fake)



combined_sentiment <- c(fake_news_testing$sentiment, real_news_testing$sentiment)

# Create a vector to indicate the source of the data (ha1 or ha2)
data_source <- c(rep("Real", nrow(fake_news_testing)), rep("Fake", nrow(real_news_testing)))

# Create a boxplot for the combined sentiment data
boxplot(combined_sentiment ~ data_source,
        main = "Boxplot of Sentiment Column for Real and Fake news",
        xlab = "Dataset",
        ylab = "Sentiment",
        col = c("skyblue", "lightgreen"),
        border = "black",
        horizontal = TRUE)
```

```{r}
real_plot <- real_news_testing |> filter(!sentiment >100) |> filter(!sentiment < -100)
fake_plot <- fake_news_testing |> filter(!sentiment >100) |> filter(!sentiment < -100)

combined_sentiment <- c(fake_plot$sentiment, real_plot$sentiment)

# Create a vector to indicate the source of the data (ha1 or ha2)
data_source <- c(rep("Fake", nrow(fake_plot)), rep("Real", nrow(real_plot)))

# Create a boxplot for the combined sentiment data
boxplot(combined_sentiment ~ data_source,
        main = "Boxplot of Sentiment Column for Real and Fake news",
        xlab = "Dataset",
        ylab = "Sentiment",
        col = c("skyblue", "lightgreen"),
        border = "black",
        horizontal = TRUE)
```

###Count capitalized words in the title

```{r}
# Count capitalized words in the title

uppers <- "\\b[:upper:]+\\b"

fake_news_testing$capitalized_words_count <- sapply(fake_news_testing$title, function(title) {
  str_count(title, uppers)
})

real_news_testing$capitalized_words_count <- sapply(real_news_testing$title, function(title) {
  str_count(title, uppers)
})


```

```{r}
# Calculate the sum of capitalized_words_count for each dataset
summarized_sum <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Sum_Capitalized_Words = c(sum(real_news_testing$capitalized_words_count),
                            sum(fake_news_testing$capitalized_words_count))
)
summarized_sum

# Calculate the mean and SD of capitalized_words_count for each dataset
summarized_mean_sd <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Mean_Capitalized_Words = c(mean(real_news_testing$capitalized_words_count),
                             mean(fake_news_testing$capitalized_words_count)),
  SD_Capitalized_Words = c(sd(real_news_testing$capitalized_words_count),
                           sd(fake_news_testing$capitalized_words_count))
)
summarized_mean_sd



# Create bar plot for the sum of capitalized words
ggplot(summarized_sum, aes(x = Dataset, y = Sum_Capitalized_Words, fill = Dataset)) +
  geom_bar(stat = "identity") +
  labs(title = "Sum of Capitalized Words in Titles",
       y = "Sum of Capitalized Words",
       fill = "Dataset") +
  theme_minimal()


# Create bar plot for the mean of capitalized words with error bars for SD
ggplot(summarized_mean_sd, aes(x = Dataset, y = Mean_Capitalized_Words, fill = Dataset)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = Mean_Capitalized_Words - SD_Capitalized_Words, ymax = Mean_Capitalized_Words + SD_Capitalized_Words), width = 0.2) +
  labs(title = "Mean of Capitalized Words in Titles with Standard Deviation",
       y = "Mean of Capitalized Words",
       fill = "Dataset") +
  theme_minimal()


```

###Count Repeated words

```{r}
# Define the thresholds
thresholds <- 6:10

# Create an empty data frame to store the results
results <- data.frame(Threshold = thresholds,
                      RealNews = NA,
                      FakeNews = NA)

# For fake news testing data
for (threshold in thresholds) {
  fake_news_testing[[paste0("repeated_words_count_", threshold)]] <- sapply(fake_news_testing$cleaned_text, function(text) {
    words <- unlist(strsplit(text, "\\s+"))  # Split text into individual words
    word_counts <- table(words)              # Count occurrences of each word
    sum(word_counts > threshold)             # Count words that appear more than the threshold
  })
  
  # Count the number of rows with repeated_words_count > threshold for fake news testing data
  results$FakeNews[results$Threshold == threshold] <- sum(fake_news_testing[[paste0("repeated_words_count_", threshold)]] > 0)
}

# For real news testing data
for (threshold in thresholds) {
  real_news_testing[[paste0("repeated_words_count_", threshold)]] <- sapply(real_news_testing$cleaned_text, function(text) {
    words <- unlist(strsplit(text, "\\s+"))  # Split text into individual words
    word_counts <- table(words)              # Count occurrences of each word
    sum(word_counts > threshold)             # Count words that appear more than the threshold
  })
  
  # Count the number of rows with repeated_words_count > threshold for real news testing data
  results$RealNews[results$Threshold == threshold] <- sum(real_news_testing[[paste0("repeated_words_count_", threshold)]] > 0)
}

# Print the results
print(results)

```

```{r}
# Create a data frame for plotting
plot_data <- data.frame(
  Threshold = results$Threshold,
  RealNews = results$RealNews,
  FakeNews = results$FakeNews
)

# Melt the data frame for easier plotting
plot_data <- reshape2::melt(plot_data, id.vars = "Threshold", variable.name = "Dataset")

# Plot the line graph
ggplot(plot_data, aes(x = Threshold, y = value, color = Dataset)) +
  geom_line() +
  labs(title = "Occurrences of Words with Thresholds",
       x = "Threshold",
       y = "Count") +
  theme_minimal()
```

```{r}
# Count the number of rows with repeated_words_count > 0 for each dataset
num_rows_with_repeated_words_real <- sum(real_news_testing$repeated_words_count > 0)
num_rows_with_repeated_words_fake <- sum(fake_news_testing$repeated_words_count > 0)

# Create a summary table
summary_table <- data.frame(
  Dataset = c("Real News", "Fake News"),
  Rows_with_repeated_words = c(num_rows_with_repeated_words_real, num_rows_with_repeated_words_fake)
)

summary_table

```
